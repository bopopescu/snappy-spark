apply plugin: 'wrapper'

// TODO: profiles and allow changing hadoopVersion

buildscript {
  repositories {
    maven { url "https://plugins.gradle.org/m2" }
  }
  dependencies {
    classpath "com.github.maiflai:gradle-scalatest:0.9"
    classpath "com.commercehub.gradle.plugin:gradle-avro-plugin:0.5.0"
  }
}

allprojects {
  // We want to see all test results.  This is equivalatent to setting --continue
  // on the command line.
  gradle.startParameter.continueOnFailure = true

  repositories {
    mavenLocal()
    mavenCentral()
    maven { url "https://repository.apache.org/content/repositories/releases" }
    maven { url "https://repository.jboss.org/nexus/content/repositories/releases" }
    maven { url "https://repo.eclipse.org/content/repositories/paho-releases" }
    maven { url "https://repository.cloudera.com/artifactory/cloudera-repos" }
    maven { url "https://oss.sonatype.org/content/repositories/orgspark-project-1113" }
    maven { url "http://repository.mapr.com/maven" }
    maven { url "https://repo.spring.io/libs-release" }
    maven { url "http://maven.twttr.com" }
    maven { url "http://repository.apache.org/snapshots" }
  }

  apply plugin: 'java'
  apply plugin: 'scala'
  apply plugin: 'maven'
  //apply plugin: "com.github.maiflai.scalatest"

  // apply compiler options
  sourceCompatibility = 1.7
  targetCompatibility = 1.7

  compileJava.options.encoding = 'UTF-8'
  compileScala.options.encoding = 'UTF-8'
  compileJava.options.compilerArgs << '-Xlint:all,-serial,-path'

  group = "org.apache.spark"
  version = "1.5.0-SNAPSHOT.1"

  ext {
    scalaBinaryVersion = "2.10"
    scalaVersion = scalaBinaryVersion + ".4"
    hadoopVersion = "2.4.1"
    jettyVersion = "8.1.14.v20131031"
    log4jVersion = "1.2.17"
    slf4jVersion = "1.7.12"
    akkaVersion = "2.3.11"
    // the netty version from akka
    akkaNettyVersion = "3.8.0.Final"
    if (rootProject.name == "snappy-spark") {
      subprojectBase = ":"
    } else {
      subprojectBase = ":snappy-spark:"
    }
  }

  dependencies {
    compile 'org.scala-lang:scala-library:' + scalaVersion
    compile 'org.scala-lang:scala-reflect:' + scalaVersion
  }
 
  // default output directory like in sbt/maven
  buildDir = "target/scala-" + scalaBinaryVersion
}

subprojects {
  // when invoking from snappy-commons, below are already defined at top-level
  if (rootProject.name == "snappy-spark") {
    task packageSources(type: Jar, dependsOn: classes) {
      classifier = 'sources'
      from sourceSets.main.allSource
    }
    task packageDocs(type: Jar, dependsOn: javadoc) {
      classifier = 'sources'
      from javadoc.destinationDir
    }
    artifacts {
      archives packageSources
      //archives packageDocs
    }

    configurations {
      testOutput {
        extendsFrom testCompile
        description 'a dependency that exposes test artifacts'
      }
    }

    task packageTests(type: Jar) {
      from sourceSets.test.output
      classifier = 'tests'
    }
    artifacts {
      testOutput packageTests
    }

    // fix scala+java mix to all use compileScala which use correct dependency order
    sourceSets.main.scala.srcDir "src/main/java"
    sourceSets.main.java.srcDirs = []
  }

  dependencies {
    // This is a dummy dependency that is used along with the shading plug-in
    // to create effective poms on publishing (see SPARK-3812).
    //compile group: 'org.spark-project.spark', name: 'unused', version:'1.0.0'

    compile group: 'com.google.guava', name: 'guava', version: '14.0.1'
    compile group: 'log4j', name:'log4j', version: log4jVersion
    compile 'org.slf4j:slf4j-api:' + slf4jVersion
    compile 'org.slf4j:slf4j-log4j12:' + slf4jVersion

    testCompile 'junit:junit:4.10'
    testCompile 'org.scalatest:scalatest_' + scalaBinaryVersion + ':2.2.1'
    testCompile 'org.mockito:mockito-core:1.9.5'
    testCompile 'org.scalacheck:scalacheck_' + scalaBinaryVersion + ':1.11.3'
    testCompile 'com.novocode:junit-interface:0.10'

    testRuntime 'org.pegdown:pegdown:1.1.0'
  }
}
